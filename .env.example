# ============================================================================
# Chimera Desktop Assistant - Environment Configuration
# ============================================================================
# Copy this file to .env and configure your preferred LLM provider
# For local development, Ollama is recommended (no API keys required)
# ============================================================================

# ----------------------------------------------------------------------------
# General Application Settings
# ----------------------------------------------------------------------------
APP_NAME="Chimera Desktop Assistant"
DEBUG=false
LOG_LEVEL=INFO

# Default LLM Provider (chimera, openai, claude, watsonx, ollama)
CHIMERA_DEFAULT_PROVIDER=ollama

# Privacy Settings
STORE_SCREENSHOTS=false
ANALYTICS_ENABLED=false

# Server Settings
HOST=127.0.0.1
PORT=8000
RELOAD=false

# Feature Flags
ENABLE_MONITORING=true
ENABLE_MULTI_MONITOR=true

# ----------------------------------------------------------------------------
# Chimera Managed Server (Default - Easiest Setup)
# ----------------------------------------------------------------------------
# Official Chimera server with pre-configured multimodal models
# Sign up at: https://chimera-ai.com/signup
# Free tier: 100 requests/day
# ----------------------------------------------------------------------------
CHIMERA_SERVER_API_URL=https://api.chimera-ai.com/v1
CHIMERA_SERVER_API_KEY=
CHIMERA_SERVER_MODEL=chimera-vision-1

# ----------------------------------------------------------------------------
# OpenAI Configuration
# ----------------------------------------------------------------------------
# Get your API key from: https://platform.openai.com/api-keys
# Recommended models: gpt-4o (best vision), gpt-4o-mini (cost-effective)
# Pricing: https://openai.com/api/pricing/
# ----------------------------------------------------------------------------
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o
OPENAI_BASE_URL=
OPENAI_TEMPERATURE=0.7
OPENAI_MAX_TOKENS=2048

# ----------------------------------------------------------------------------
# Anthropic Claude Configuration
# ----------------------------------------------------------------------------
# Get your API key from: https://console.anthropic.com/settings/keys
# Recommended models: claude-3-5-sonnet-20241022, claude-3-5-haiku-20241022
# Pricing: https://www.anthropic.com/pricing
# ----------------------------------------------------------------------------
ANTHROPIC_API_KEY=
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022
ANTHROPIC_BASE_URL=
ANTHROPIC_VERSION=2023-06-01
ANTHROPIC_TEMPERATURE=0.7
ANTHROPIC_MAX_TOKENS=2048

# ----------------------------------------------------------------------------
# IBM Watsonx Configuration
# ----------------------------------------------------------------------------
# Get your API key from: https://cloud.ibm.com/iam/apikeys
# Project ID from: https://dataplatform.cloud.ibm.com/projects
# Recommended models: ibm/granite-3-8b-instruct, meta-llama/llama-3-1-70b-instruct
# ----------------------------------------------------------------------------
WATSONX_API_KEY=
WATSONX_PROJECT_ID=
WATSONX_MODEL_ID=ibm/granite-3-8b-instruct
WATSONX_BASE_URL=https://us-south.ml.cloud.ibm.com
WATSONX_TEMPERATURE=0.3
WATSONX_MAX_TOKENS=1024

# ----------------------------------------------------------------------------
# Ollama Configuration (Local Models - No API Keys Required!)
# ----------------------------------------------------------------------------
# Install Ollama: https://ollama.com/download
# Quick start: ./scripts/setup_ollama.sh
# Recommended vision models: llava:latest, llava:13b, bakllava
# Recommended code models: deepseek-coder:latest, codellama:latest
# Recommended fast models: gemma:2b, phi3:mini, qwen2:1.5b
# ----------------------------------------------------------------------------
OLLAMA_BASE_URL=http://127.0.0.1:11434
OLLAMA_MODEL=llava:latest
OLLAMA_TEMPERATURE=0.7
OLLAMA_TIMEOUT=120

# ----------------------------------------------------------------------------
# Provider-Specific Notes
# ----------------------------------------------------------------------------
#
# Chimera Server:
#   - Managed hosting with multimodal models
#   - No setup required, just API key
#   - Best for production deployments
#   - Free tier available
#
# OpenAI:
#   - Best-in-class vision models (GPT-4o)
#   - Requires paid API key
#   - Fast inference, high quality
#   - $2.50-$10 per 1M tokens
#
# Claude:
#   - Excellent reasoning and code analysis
#   - Requires paid API key
#   - Strong privacy and safety features
#   - $3-$15 per 1M tokens
#
# Watsonx:
#   - Enterprise IBM platform
#   - Open source models (Llama, Granite, Mistral)
#   - Requires IBM Cloud account
#   - Free tier available
#
# Ollama (Recommended for Development):
#   - 100% free and open source
#   - Runs locally on your machine
#   - No API keys or internet required
#   - Privacy-first: no data leaves your computer
#   - Supports 50+ models (llava, llama3, gemma, etc.)
#   - Setup: ./scripts/setup_ollama.sh
#
# ----------------------------------------------------------------------------
# Quick Start Guide
# ----------------------------------------------------------------------------
#
# 1. For local development (recommended):
#    - Set CHIMERA_DEFAULT_PROVIDER=ollama
#    - Run: ./scripts/setup_ollama.sh
#    - Done! No API keys needed
#
# 2. For production with OpenAI:
#    - Set CHIMERA_DEFAULT_PROVIDER=openai
#    - Get API key from https://platform.openai.com/api-keys
#    - Set OPENAI_API_KEY=sk-...
#    - Set OPENAI_MODEL=gpt-4o
#
# 3. For enterprise with Watsonx:
#    - Set CHIMERA_DEFAULT_PROVIDER=watsonx
#    - Get credentials from IBM Cloud
#    - Set WATSONX_API_KEY and WATSONX_PROJECT_ID
#
# ----------------------------------------------------------------------------
